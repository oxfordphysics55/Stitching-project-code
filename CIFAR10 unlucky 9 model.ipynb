{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "829607ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8353731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Original training set size: 50000\n",
      "Training set size without class 9: 45000\n",
      "Training set size with only class 9: 5000\n"
     ]
    }
   ],
   "source": [
    "# Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the full CIFAR-10 dataset\n",
    "full_trainset = torchvision.datasets.CIFAR10(root='./data/', train=True, download=True, transform=transform)\n",
    "full_testset = torchvision.datasets.CIFAR10(root='./data/', train=False, download=True, transform=transform)\n",
    "\n",
    "# Filter dataset: Exclude class 9\n",
    "filtered_train_data_no_9 = [(img, label) for img, label in full_trainset if label != 9]\n",
    "filtered_train_images_no_9, filtered_train_labels_no_9 = zip(*filtered_train_data_no_9)\n",
    "\n",
    "# Filter dataset: Only class 9\n",
    "filtered_train_data_only_9 = [(img, label) for img, label in full_trainset if label == 9]\n",
    "filtered_train_images_only_9, filtered_train_labels_only_9 = zip(*filtered_train_data_only_9)\n",
    "\n",
    "# Create dataset without class 9\n",
    "trainset_no_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_train_images_no_9), torch.tensor(filtered_train_labels_no_9)\n",
    ")\n",
    "trainloader_no_9 = torch.utils.data.DataLoader(trainset_no_9, batch_size=4, shuffle=True)\n",
    "\n",
    "# Create dataset with only class 9\n",
    "trainset_only_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_train_images_only_9), torch.tensor(filtered_train_labels_only_9)\n",
    ")\n",
    "trainloader_only_9 = torch.utils.data.DataLoader(trainset_only_9, batch_size=4, shuffle=True)\n",
    "\n",
    "# Filter testset: Exclude class 9\n",
    "filtered_test_data_no_9 = [(img, label) for img, label in full_testset if label != 9]\n",
    "filtered_test_images_no_9, filtered_test_labels_no_9 = zip(*filtered_test_data_no_9)\n",
    "\n",
    "# Filter dataset: Only class 9\n",
    "filtered_test_data_only_9 = [(img, label) for img, label in full_testset if label == 9]\n",
    "filtered_test_images_only_9, filtered_test_labels_only_9 = zip(*filtered_test_data_only_9)\n",
    "\n",
    "# Create test dataset without class 9\n",
    "testset_no_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_test_images_no_9), torch.tensor(filtered_test_labels_no_9)\n",
    ")\n",
    "testloader_no_9 = torch.utils.data.DataLoader(testset_no_9, batch_size=4, shuffle=True)\n",
    "\n",
    "# Create test dataset with only class 9\n",
    "testset_only_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_test_images_only_9), torch.tensor(filtered_test_labels_only_9)\n",
    ")\n",
    "testloader_only_9 = torch.utils.data.DataLoader(testset_only_9, batch_size=4, shuffle=True)\n",
    "\n",
    "\n",
    "# Normal trainloader (all classes)\n",
    "trainloader_full = torch.utils.data.DataLoader(full_trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Normal testloader (unchanged)\n",
    "testloader = torch.utils.data.DataLoader(full_testset, batch_size=4, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Original training set size: {len(full_trainset)}\")\n",
    "print(f\"Training set size without class 9: {len(trainset_no_9)}\")\n",
    "print(f\"Training set size with only class 9: {len(trainset_only_9)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "691e24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 84)\n",
    "        #self.fc4 = nn.Linear(84, 84)\n",
    "        self.fc5 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1d78b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce47dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "model_directory_path = 'model/'\n",
    "model_path = os.path.join(model_directory_path, 'cifar-mnist-cnn-model.pt')\n",
    "\n",
    "# Ensure directory exists\n",
    "if not os.path.exists(model_directory_path):\n",
    "    os.makedirs(model_directory_path)\n",
    "\n",
    "def load_model(net):\n",
    "    \"\"\"Loads the trained model if it exists.\"\"\"\n",
    "    if os.path.isfile(model_path):\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "        print('Loaded model parameters from disk.')\n",
    "        return True  # Indicate successful loading\n",
    "    else:\n",
    "        print('No saved model found.')\n",
    "        return False\n",
    "\n",
    "def train_model(net, trainloader, criterion, optimizer, epochs=2):\n",
    "    \"\"\"Trains the model from scratch.\"\"\"\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # Print every 200 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0bf6acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_training(net, trainloader, criterion, optimizer, epochs=2):\n",
    "\n",
    "    # Freeze all layers initially\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    #Unfreeze single layer\n",
    "    for param in net.fc1.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if trainloader == trainloader_only_9:\n",
    "                if i % 200 == 199:  # Print every 200 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "            elif trainloader == trainloader_full:\n",
    "                if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "    print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5780d6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1,  2000] loss: 2.158\n",
      "[1,  4000] loss: 1.847\n",
      "[1,  6000] loss: 1.648\n",
      "[1,  8000] loss: 1.574\n",
      "[1, 10000] loss: 1.482\n",
      "[2,  2000] loss: 1.400\n",
      "[2,  4000] loss: 1.362\n",
      "[2,  6000] loss: 1.342\n",
      "[2,  8000] loss: 1.312\n",
      "[2, 10000] loss: 1.293\n",
      "[3,  2000] loss: 1.202\n",
      "[3,  4000] loss: 1.213\n",
      "[3,  6000] loss: 1.206\n",
      "[3,  8000] loss: 1.195\n",
      "[3, 10000] loss: 1.173\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "train_model(net, trainloader_no_9, criterion, optimizer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed369be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.162\n",
      "[1,   400] loss: 0.152\n",
      "[1,   600] loss: 0.157\n",
      "[1,   800] loss: 0.152\n",
      "[1,  1000] loss: 0.145\n",
      "[1,  1200] loss: 0.141\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "layer_training(net, trainloader_only_9, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "760e108e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.172\n",
      "[1,  4000] loss: 1.161\n",
      "[1,  6000] loss: 1.181\n",
      "[1,  8000] loss: 1.177\n",
      "[1, 10000] loss: 1.181\n",
      "[1, 12000] loss: 1.170\n",
      "[2,  2000] loss: 1.169\n",
      "[2,  4000] loss: 1.180\n",
      "[2,  6000] loss: 1.174\n",
      "[2,  8000] loss: 1.162\n",
      "[2, 10000] loss: 1.181\n",
      "[2, 12000] loss: 1.169\n",
      "[3,  2000] loss: 1.177\n",
      "[3,  4000] loss: 1.182\n",
      "[3,  6000] loss: 1.161\n",
      "[3,  8000] loss: 1.165\n",
      "[3, 10000] loss: 1.186\n",
      "[3, 12000] loss: 1.171\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "layer_training(net, trainloader_full, criterion, optimizer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bbacdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on 10000 test images: 52.84%\n",
      "Model accuracy on test set with only class 9: 0.00%\n",
      "Model accuracy on test set without class 9: 58.71%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_full(net, testloader)\n",
    "evaluate_model_only_9(net, testloader_only_9)\n",
    "evaluate_model_no_9(net, testloader_no_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f47979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2ffe8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def evaluate_model_only_9(model, testloader_only_9):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    confusion_matrix = np.zeros([10, 10], int)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader_only_9:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            for i, l in enumerate(labels):\n",
    "                confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "    only_9_accuracy = total_correct / total_images * 100\n",
    "    print(f'Model accuracy on test set with only class 9: {only_9_accuracy:.2f}%')\n",
    "    \n",
    "def evaluate_model_no_9(model, testloader_no_9):\n",
    "    model.eval() \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    confusion_matrix = np.zeros([10, 10], int)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader_no_9:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            for i, l in enumerate(labels):\n",
    "                confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "    no_9_accuracy = total_correct / total_images * 100\n",
    "    print(f'Model accuracy on test set without class 9: {no_9_accuracy:.2f}%')\n",
    "    \n",
    "def evaluate_model_full(model, testloader):\n",
    "    model.eval() \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "    confusion_matrix = np.zeros([10, 10], int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_images += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            for i, l in enumerate(labels):\n",
    "                confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "    model_accuracy = total_correct / total_images * 100\n",
    "    print(f'Model accuracy on {total_images} test images: {model_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a55adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5313cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3dfa0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net\n",
    "torch.save(model, 'model_unlucky_9_2e_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7ebea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
