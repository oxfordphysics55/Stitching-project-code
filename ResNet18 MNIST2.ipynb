{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b53b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d2261d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "batch_size = 4\n",
    "trainset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "\n",
    "testset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfb483fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Show some sample images and their labels\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m      5\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_iter)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert tensor to numpy for visualization\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show some sample images and their labels\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Convert tensor to numpy for visualization\n",
    "images = images.numpy()\n",
    "labels = labels.numpy()\n",
    "\n",
    "# Plot the first 5 images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(images[i].transpose(1, 2, 0))  # Transpose to (height, width, channels)\n",
    "    ax.set_title(f\"Label: {labels[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "899b9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b47862ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [3]\n",
    "\n",
    "# Load the pretrained ResNet-18 model\n",
    "model1b = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to match CIFAR-10 (10 classes)\n",
    "model1b.fc = nn.Linear(model1b.fc.in_features, 10)\n",
    "\n",
    "#Change to one input channel to satisy MNIST\n",
    "model1b.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "\n",
    "# Load the pretrained ResNet-18 model\n",
    "model2b = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to match CIFAR-10 (10 classes)\n",
    "model2b.fc = nn.Linear(model2b.fc.in_features, 10)\n",
    "\n",
    "#Change to one input channel to satisy MNIST\n",
    "model2b.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad61059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function (CrossEntropyLoss) and optimizer (SGD)\n",
    "weight_decay = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model1b.parameters(), lr=0.001, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c900614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2929\n",
      "Epoch [2/10], Loss: 0.0995\n",
      "Epoch [3/10], Loss: 0.0663\n",
      "Epoch [4/10], Loss: 0.0509\n",
      "Epoch [5/10], Loss: 0.0431\n",
      "Epoch [6/10], Loss: 0.0340\n",
      "Epoch [7/10], Loss: 0.0307\n",
      "Epoch [8/10], Loss: 0.0238\n",
      "Epoch [9/10], Loss: 0.0234\n",
      "Epoch [10/10], Loss: 0.0223\n"
     ]
    }
   ],
   "source": [
    "# Define loss function (CrossEntropyLoss) and optimizer (SGD)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model1b.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model1b.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1b(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
    "    \n",
    "    \n",
    "torch.save(model1b, 'ResNet18_1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41396958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 34.7669\n",
      "Epoch [2/10], Loss: 31.1515\n",
      "Epoch [3/10], Loss: 27.5680\n",
      "Epoch [4/10], Loss: 24.3758\n",
      "Epoch [5/10], Loss: 21.4816\n",
      "Epoch [6/10], Loss: 20.0915\n",
      "Epoch [7/10], Loss: 18.7932\n",
      "Epoch [8/10], Loss: 17.7406\n",
      "Epoch [9/10], Loss: 16.3833\n",
      "Epoch [10/10], Loss: 15.2763\n"
     ]
    }
   ],
   "source": [
    "#This trains a model which is hopefully simpler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.quantization\n",
    "\n",
    "# L1 Regularization function\n",
    "def l1_regularization(model2b, l1_weight=0.0001):\n",
    "    l1_norm = 0\n",
    "    for param in model2b.parameters():\n",
    "        l1_norm += torch.sum(torch.abs(param))\n",
    "    return l1_weight * l1_norm\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model2b.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "num_epochs = 10\n",
    "\n",
    "def gradual_pruning(model2b, start_epoch, total_epochs, amount_per_step):\n",
    "    for module in model2b.modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount_per_step * (start_epoch / total_epochs))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model2b.train()\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2b(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # L1 regularization\n",
    "        l1_loss = sum(torch.norm(p, 1) for p in model2b.parameters())\n",
    "        loss += 0.00005 * l1_loss  # Scale L1 loss properly\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Apply pruning gradually\n",
    "    gradual_pruning(model2b, epoch + 1, num_epochs, amount_per_step=0.01)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    scheduler.step()  # Adjust learning rate\n",
    "    \n",
    "torch.save(model2b, 'ResNet18_2b.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e17602da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002820927505323198"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss_sharpness(model1b, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e5cfc045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.528636578786373"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient_norm(model1b, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3272bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compress_model_numpy(model1b)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1b' is not defined"
     ]
    }
   ],
   "source": [
    "compress_model_numpy(model1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f22c953a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011567579325346742"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss_sharpness(model2b, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff00c4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5663941181335599"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient_norm(model2b, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dad7cbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343955984"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_model_numpy(model2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6db555",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compute_loss_sharpness(model3b, criterion, test_loader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3b' is not defined"
     ]
    }
   ],
   "source": [
    "compute_loss_sharpness(model3b, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169c893f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compute_gradient_norm(model3b, criterion, test_loader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3b' is not defined"
     ]
    }
   ],
   "source": [
    "compute_gradient_norm(model3b, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accff550",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compress_model_numpy(model3b)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3b' is not defined"
     ]
    }
   ],
   "source": [
    "compress_model_numpy(model3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36a8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "def compute_loss_sharpness(model, loss_fn, testloader, epsilon=1e-3):\n",
    "    \"\"\"Computes the sharpness measure by perturbing model parameters without modifying the original model.\"\"\"\n",
    "    model.eval()\n",
    "    total_sharpness = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(next(model.parameters()).device), target.to(next(model.parameters()).device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            original_loss = loss_fn(output, target).item()\n",
    "\n",
    "        # Clone model\n",
    "        perturbed_model = copy.deepcopy(model)\n",
    "        perturbed_model.to(next(model.parameters()).device)\n",
    "\n",
    "        # Apply perturbation to the cloned model's parameters\n",
    "        with torch.no_grad():\n",
    "            for p in perturbed_model.parameters():\n",
    "                p.add_(epsilon * torch.randn_like(p))  # Apply perturbation directly\n",
    "\n",
    "        # Compute loss with perturbed parameters\n",
    "        with torch.no_grad():\n",
    "            perturbed_output = perturbed_model(data)\n",
    "            perturbed_loss = loss_fn(perturbed_output, target).item()\n",
    "\n",
    "        total_sharpness += perturbed_loss - original_loss\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_sharpness / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "def compute_gradient_norm(model, loss_fn, testloader):\n",
    "    \"\"\"Computes the average gradient norm over the test set without modifying the model state.\"\"\"\n",
    "    model.eval()\n",
    "    total_norm = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(next(model.parameters()).device), target.to(next(model.parameters()).device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        batch_norm = torch.sqrt(sum(p.grad.norm()**2 for p in model.parameters() if p.grad is not None))\n",
    "        total_norm += batch_norm.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_norm / num_batches if num_batches > 0 else 0.0\n",
    "\n",
    "def compress_model_numpy(model):\n",
    "    \"\"\"Compresses the model's parameters into a bit stream.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        weights = np.concatenate([p.cpu().detach().numpy().flatten() for p in model.parameters()])\n",
    "    model_bytes = pickle.dumps(weights)\n",
    "    compressed = gzip.compress(model_bytes)\n",
    "    return len(compressed) * 8  # Size in bits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "11a4c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Stitching): StitchingLayer(\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class StitchingLayer(nn.Module):\n",
    "    def __init__(self, C1, C2):\n",
    "        super(StitchingLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(C1)\n",
    "        self.conv1x1 = nn.Conv2d(in_channels=C1, out_channels=C2, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(C2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "      \n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.Stitching = StitchingLayer(64, 64)  # Added StitchingLayer\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, out_channels, blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(BasicBlock(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.Stitching(x)  # Pass through StitchingLayer\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model3b = ResNet18(num_classes=10)\n",
    "#Change to one input channel to satisy MNIST\n",
    "model3b.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "print(model3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "63260988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I switch keys 1 and keys 2 to flip the stitching order\n",
    "\n",
    "# Get the state_dict for each model\n",
    "state_dict_2 = model1b.state_dict()\n",
    "state_dict_1 = model2b.state_dict()\n",
    "state_dict_3 = model3b.state_dict()\n",
    "\n",
    "# Identify keys for copying\n",
    "keys_1 = list(state_dict_1.keys())\n",
    "keys_2 = list(state_dict_2.keys())\n",
    "keys_3 = list(state_dict_3.keys())\n",
    "\n",
    "# Mapping function to handle different key formats\n",
    "def get_matching_key(key, source_keys):\n",
    "    if key in source_keys:\n",
    "        return key\n",
    "    if key.startswith(\"0.\") and key[2:] in source_keys:\n",
    "        return key[2:]  # Remove '0.' prefix if necessary\n",
    "    if key.endswith(\"_orig\") and key[:-5] in source_keys:\n",
    "        return key[:-5]  # Remove '_orig' suffix if necessary\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5c33cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_3:\n",
    "    match_key_1 = get_matching_key(key, keys_1)\n",
    "    match_key_2 = get_matching_key(key, keys_2)\n",
    "    \n",
    "    if \"conv1\" in key or \"bn1\" in key or \"maxpool\" in key:\n",
    "        if match_key_2:\n",
    "            state_dict_3[key] = state_dict_2[match_key_2]\n",
    "    elif \"layer1\" in key or \"layer2\" in key or \"layer3\" in key or \"layer4\" in key or \"fc\" in key:\n",
    "        if match_key_1:\n",
    "            state_dict_3[key] = state_dict_1[match_key_1]\n",
    "    elif \"stitching\" in key:\n",
    "        print(f\"Skipping {key}, keeping original initialization for StitchingLayer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3586529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_3:\n",
    "    match_key_1 = get_matching_key(key, keys_1)\n",
    "    match_key_2 = get_matching_key(key, keys_2)\n",
    "    \n",
    "    if \"layer1\" in key or \"conv1\" in key or \"bn1\" in key or \"maxpool\" in key:\n",
    "        if match_key_2:\n",
    "            state_dict_3[key] = state_dict_2[match_key_2]\n",
    "    elif \"layer2\" in key or \"layer3\" in key or \"layer4\" in key or \"fc\" in key:\n",
    "        if match_key_1:\n",
    "            state_dict_3[key] = state_dict_1[match_key_1]\n",
    "    elif \"stitching\" in key:\n",
    "        print(f\"Skipping {key}, keeping original initialization for StitchingLayer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7c618412",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[259], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbn1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxpool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_key_2:\n\u001b[0;32m----> 7\u001b[0m         state_dict_3[key] \u001b[38;5;241m=\u001b[39m state_dict_2[match_key_2]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer4\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_key_1:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1.weight'"
     ]
    }
   ],
   "source": [
    "for key in keys_3:\n",
    "    match_key_1 = get_matching_key(key, keys_1)\n",
    "    match_key_2 = get_matching_key(key, keys_2)\n",
    "    \n",
    "    if \"layer1\" in key or \"layer2\" in key or \"conv1\" in key or \"bn1\" in key or \"maxpool\" in key:\n",
    "        if match_key_2:\n",
    "            state_dict_3[key] = state_dict_2[match_key_2]\n",
    "    elif \"layer3\" in key or \"layer4\" in key or \"fc\" in key:\n",
    "        if match_key_1:\n",
    "            state_dict_3[key] = state_dict_1[match_key_1]\n",
    "    elif \"stitching\" in key:\n",
    "        print(f\"Skipping {key}, keeping original initialization for StitchingLayer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a94702ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[260], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbn1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxpool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_key_2:\n\u001b[0;32m----> 7\u001b[0m         state_dict_3[key] \u001b[38;5;241m=\u001b[39m state_dict_2[match_key_2]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer4\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_key_1:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1.weight'"
     ]
    }
   ],
   "source": [
    "for key in keys_3:\n",
    "    match_key_1 = get_matching_key(key, keys_1)\n",
    "    match_key_2 = get_matching_key(key, keys_2)\n",
    "    \n",
    "    if \"layer1\" in key or \"layer2\" in key or \"layer3\" in key or \"conv1\" in key or \"bn1\" in key or \"maxpool\" in key:\n",
    "        if match_key_2:\n",
    "            state_dict_3[key] = state_dict_2[match_key_2]\n",
    "    elif \"layer4\" in key or \"fc\" in key:\n",
    "        if match_key_1:\n",
    "            state_dict_3[key] = state_dict_1[match_key_1]\n",
    "    elif \"stitching\" in key:\n",
    "        print(f\"Skipping {key}, keeping original initialization for StitchingLayer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "99187b9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[261], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer4\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbn1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxpool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_key_2:\n\u001b[0;32m----> 7\u001b[0m         state_dict_3[key] \u001b[38;5;241m=\u001b[39m state_dict_2[match_key_2]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_key_1:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1.weight'"
     ]
    }
   ],
   "source": [
    "for key in keys_3:\n",
    "    match_key_1 = get_matching_key(key, keys_1)\n",
    "    match_key_2 = get_matching_key(key, keys_2)\n",
    "    \n",
    "    if \"layer1\" in key or \"layer2\" in key or \"layer3\" in key or \"layer4\" in key or \"conv1\" in key or \"bn1\" in key or \"maxpool\" in key:\n",
    "        if match_key_2:\n",
    "            state_dict_3[key] = state_dict_2[match_key_2]\n",
    "    elif \"fc\" in key:\n",
    "        if match_key_1:\n",
    "            state_dict_3[key] = state_dict_1[match_key_1]\n",
    "    elif \"stitching\" in key:\n",
    "        print(f\"Skipping {key}, keeping original initialization for StitchingLayer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "bbb2d8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the modified state_dict into model3b\n",
    "model3b.load_state_dict(state_dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "32af89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(state_dict_3.keys())  # Check available keys\n",
    "#print(state_dict_1.keys())  # Check keys in model1b\n",
    "#print(state_dict_2.keys())  # Check keys in model2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1053ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stitching_layer(model3b, dataloader, criterion, optimizer, num_epochs=5):\n",
    "    # Loop through all model parameters\n",
    "    for name, param in model3b.named_parameters():\n",
    "        if 'Stitching' in name:  # Ensure we target the stitching layer by checking its name\n",
    "            param.requires_grad = True  # Allow gradients for the stitching layer\n",
    "        else:\n",
    "            param.requires_grad = False  # Freeze other layers\n",
    "\n",
    "    model3b.to(device)\n",
    "    model3b.train()  # Set the model to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model3b(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "            loss.backward()  # Backpropagate to calculate gradients\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()  # Accumulate loss for this epoch\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
    "    \n",
    "    print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6db7e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model3b.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3b6b551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Loss: 1.9945985894560814\n",
      "Epoch 2/8, Loss: 1.7686700324932734\n",
      "Epoch 3/8, Loss: 1.7078521644592286\n",
      "Epoch 4/8, Loss: 1.6757902341961861\n",
      "Epoch 5/8, Loss: 1.6541664885878562\n",
      "Epoch 6/8, Loss: 1.6338566869735718\n",
      "Epoch 7/8, Loss: 1.6263411907394727\n",
      "Epoch 8/8, Loss: 1.612358313147227\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "train_stitching_layer(model3b, trainloader, criterion, optimizer, num_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ea4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a2da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df2a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd70f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e96f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb3965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8344d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0d14efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "\n",
    "class StitchingLayer(nn.Module):\n",
    "    def __init__(self, C1, C2):\n",
    "        super(StitchingLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(C1)\n",
    "        self.conv1x1 = nn.Conv2d(in_channels=C1, out_channels=C2, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(C2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1x1(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "def get_last_conv_out_channels(layer):\n",
    "    \"\"\"Helper function to get output channels from the last Conv2d layer in a given layer/block.\"\"\"\n",
    "    if isinstance(layer, nn.Sequential):  \n",
    "        last_block = list(layer.children())[-1]  # Get the last BasicBlock\n",
    "        if isinstance(last_block, nn.Module):  \n",
    "            for sub_layer in reversed(list(last_block.children())):  \n",
    "                if isinstance(sub_layer, nn.Conv2d):  \n",
    "                    return sub_layer.out_channels\n",
    "    return None\n",
    "\n",
    "def get_first_conv_in_channels(layer):\n",
    "    \"\"\"Helper function to get input channels from the first Conv2d layer in a given layer/block.\"\"\"\n",
    "    if isinstance(layer, nn.Sequential):  \n",
    "        first_block = list(layer.children())[0]  # Get the first BasicBlock\n",
    "        if isinstance(first_block, nn.Module):  \n",
    "            for sub_layer in list(first_block.children()):  \n",
    "                if isinstance(sub_layer, nn.Conv2d):  \n",
    "                    return sub_layer.in_channels\n",
    "    return None\n",
    "\n",
    "def insert_stitching_layer(model, target_layer_name):\n",
    "    \"\"\"\n",
    "    Inserts a stitching layer after the specified layer in ResNet.\n",
    "    Automatically detects C1 (output channels of target layer) and C2 (input channels of next layer).\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The original ResNet model.\n",
    "        target_layer_name (str): The layer after which to insert the stitching layer.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: Modified ResNet model with the stitching layer inserted.\n",
    "    \"\"\"\n",
    "    # Create a deep copy of the model so we don't modify the original\n",
    "    new_model = copy.deepcopy(model)\n",
    "\n",
    "    # Get all named layers in order\n",
    "    layers = list(new_model.named_children())\n",
    "\n",
    "    # Find C1 (output channels of the target layer) and C2 (input channels of the next layer)\n",
    "    C1, C2 = None, None\n",
    "    for i, (name, module) in enumerate(layers):\n",
    "        if name == target_layer_name:\n",
    "            C1 = get_last_conv_out_channels(module)  # Get C1 from the last conv layer in target block\n",
    "            if i + 1 < len(layers):  # Ensure there's a next layer\n",
    "                C2 = get_first_conv_in_channels(layers[i + 1][1])  # Get C2 from the first conv layer in next block\n",
    "            break\n",
    "\n",
    "    if C1 is None or C2 is None:\n",
    "        raise ValueError(f\"Could not determine C1 and C2 for layer '{target_layer_name}'. Check layer names.\")\n",
    "\n",
    "    # Create new layer sequence with stitching inserted\n",
    "    new_layers = nn.Sequential()\n",
    "    for name, module in layers:\n",
    "        new_layers.add_module(name, module)  # Add existing layer\n",
    "        if name == target_layer_name:  # If this is the target layer\n",
    "            stitching = StitchingLayer(C1, C2)\n",
    "            new_layers.add_module(\"stitching_layer\", stitching)  # Insert stitching layer\n",
    "\n",
    "    # Rebuild the model with modified layers\n",
    "    new_model = nn.Sequential(new_layers)\n",
    "\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "01e36f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (stitching_layer): StitchingLayer(\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model3b = models.resnet18(pretrained=True)\n",
    "target_layer_name = \"layer1\"\n",
    "model3b = insert_stitching_layer(model3b, target_layer_name)\n",
    "\n",
    "# Print model to verify placement\n",
    "print(model3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2be8d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def transfer_weights(model3b, model1b, model2b, stitching_layer_name=\"stitching_layer\"):\n",
    "    model3b_state_dict = model3b.state_dict()\n",
    "    model1b_state_dict = model1b.state_dict()\n",
    "    model2b_state_dict = model2b.state_dict()\n",
    "    \n",
    "    stitching_found = False\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for name, param in model3b_state_dict.items():\n",
    "        if stitching_layer_name in name:\n",
    "            stitching_found = True\n",
    "        \n",
    "        if not stitching_found:  # Before stitching layer, copy from model1b\n",
    "            if name in model1b_state_dict:\n",
    "                new_state_dict[name] = model1b_state_dict[name].clone()\n",
    "            else:\n",
    "                raise KeyError(f\"{name} not found in model1b\")\n",
    "        else:  # After stitching layer, copy from model2b\n",
    "            if name in model2b_state_dict:\n",
    "                new_state_dict[name] = model2b_state_dict[name].clone()\n",
    "            else:\n",
    "                raise KeyError(f\"{name} not found in model2b\")\n",
    "    \n",
    "    model3b.load_state_dict(new_state_dict)\n",
    "    return model3b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a5df95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stitching_layer(model3b, dataloader, criterion, optimizer, num_epochs=5):\n",
    "    for name, param in model3b.named_parameters():\n",
    "        stitching_layer_name =\"stitching_layer\"\n",
    "        if stitching_layer_name in name:\n",
    "            param.requires_grad = True  # Keep stitching layer trainable\n",
    "        else:\n",
    "            param.requires_grad = False  # Freeze all other layers\n",
    "    model3b.to(device)\n",
    "    model3b.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model3b(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
    "    \n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "931bd452",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_stitching_layer(model3b, trainloader, criterion, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 18\u001b[0m, in \u001b[0;36mtrain_stitching_layer\u001b[0;34m(model3b, dataloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear previous gradients\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model3b(inputs)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)  \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backpropagate to calculate gradients\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[36], line 86\u001b[0m, in \u001b[0;36mResNet18.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m---> 86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m     87\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mStitching(x)  \u001b[38;5;66;03m# Pass through StitchingLayer\u001b[39;00m\n\u001b[1;32m     88\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[36], line 21\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[0;32m---> 21\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1732\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1729\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1734\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_stitching_layer(model3b, trainloader, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e6b8c3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "50f30048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on 10000 test images: 58.92%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy test\n",
    "total_correct = 0\n",
    "total_images = 0\n",
    "confusion_matrix = np.zeros([10,10], int)\n",
    "net = model3b\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_images += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        for i, l in enumerate(labels):\n",
    "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "model_accuracy = total_correct / total_images * 100\n",
    "print('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335d8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159bab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4784559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a2162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5d858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
