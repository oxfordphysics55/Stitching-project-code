{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829607ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8353731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Original training set size: 50000\n",
      "Training set size without class 9: 45000\n",
      "Training set size with only class 9: 5000\n"
     ]
    }
   ],
   "source": [
    "# Define transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the full CIFAR-10 dataset\n",
    "full_trainset = torchvision.datasets.CIFAR10(root='./data/', train=True, download=True, transform=transform)\n",
    "full_testset = torchvision.datasets.CIFAR10(root='./data/', train=False, download=True, transform=transform)\n",
    "\n",
    "# Filter dataset: Exclude class 9\n",
    "filtered_train_data_no_9 = [(img, label) for img, label in full_trainset if label != 9]\n",
    "filtered_train_images_no_9, filtered_train_labels_no_9 = zip(*filtered_train_data_no_9)\n",
    "\n",
    "# Filter dataset: Only class 9\n",
    "filtered_train_data_only_9 = [(img, label) for img, label in full_trainset if label == 9]\n",
    "filtered_train_images_only_9, filtered_train_labels_only_9 = zip(*filtered_train_data_only_9)\n",
    "\n",
    "# Create dataset without class 9\n",
    "trainset_no_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_train_images_no_9), torch.tensor(filtered_train_labels_no_9)\n",
    ")\n",
    "trainloader_no_9 = torch.utils.data.DataLoader(trainset_no_9, batch_size=4, shuffle=True)\n",
    "\n",
    "# Create dataset with only class 9\n",
    "trainset_only_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_train_images_only_9), torch.tensor(filtered_train_labels_only_9)\n",
    ")\n",
    "trainloader_only_9 = torch.utils.data.DataLoader(trainset_only_9, batch_size=4, shuffle=True)\n",
    "\n",
    "# Filter testset: Exclude class 9\n",
    "filtered_test_data_no_9 = [(img, label) for img, label in full_testset if label != 9]\n",
    "filtered_test_images_no_9, filtered_test_labels_no_9 = zip(*filtered_test_data_no_9)\n",
    "\n",
    "# Filter dataset: Only class 9\n",
    "filtered_test_data_only_9 = [(img, label) for img, label in full_testset if label == 9]\n",
    "filtered_test_images_only_9, filtered_test_labels_only_9 = zip(*filtered_test_data_only_9)\n",
    "\n",
    "# Create test dataset without class 9\n",
    "testset_no_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_test_images_no_9), torch.tensor(filtered_test_labels_no_9)\n",
    ")\n",
    "testloader_no_9 = torch.utils.data.DataLoader(testset_no_9, batch_size=4, shuffle=True)\n",
    "\n",
    "# Create test dataset with only class 9\n",
    "testset_only_9 = torch.utils.data.TensorDataset(\n",
    "    torch.stack(filtered_test_images_only_9), torch.tensor(filtered_test_labels_only_9)\n",
    ")\n",
    "testloader_only_9 = torch.utils.data.DataLoader(testset_only_9, batch_size=4, shuffle=True)\n",
    "\n",
    "\n",
    "# Normal trainloader (all classes)\n",
    "trainloader_full = torch.utils.data.DataLoader(full_trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Normal testloader (unchanged)\n",
    "testloader = torch.utils.data.DataLoader(full_testset, batch_size=4, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Original training set size: {len(full_trainset)}\")\n",
    "print(f\"Training set size without class 9: {len(trainset_no_9)}\")\n",
    "print(f\"Training set size with only class 9: {len(trainset_only_9)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691e24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 84)\n",
    "        #self.fc4 = nn.Linear(84, 84)\n",
    "        self.fc5 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x), inplace = True)\n",
    "        x = F.relu(self.fc2(x), inplace = True)\n",
    "        x = F.relu(self.fc3(x), inplace = True)\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d78b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce47dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "model_directory_path = 'model/'\n",
    "model_path = os.path.join(model_directory_path, 'cifar-mnist-cnn-model.pt')\n",
    "\n",
    "# Ensure directory exists\n",
    "if not os.path.exists(model_directory_path):\n",
    "    os.makedirs(model_directory_path)\n",
    "\n",
    "def load_model(net):\n",
    "    \"\"\"Loads the trained model if it exists.\"\"\"\n",
    "    if os.path.isfile(model_path):\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "        print('Loaded model parameters from disk.')\n",
    "        return True  # Indicate successful loading\n",
    "    else:\n",
    "        print('No saved model found.')\n",
    "        return False\n",
    "\n",
    "def train_model(net, trainloader, criterion, optimizer, epochs=2):\n",
    "    \"\"\"Trains the model from scratch.\"\"\"\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # Print every 200 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b52171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_training(net, trainloader, criterion, optimizer, epochs=2):\n",
    "\n",
    "    # Freeze all layers initially\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    #Unfreeze single layer\n",
    "    for param in net.fc1.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if trainloader == trainloader_only_9:\n",
    "                if i % 200 == 199:  # Print every 200 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "            elif trainloader == trainloader_full:\n",
    "                if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "    print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5780d6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1,  2000] loss: 0.904\n",
      "[1,  4000] loss: 0.887\n",
      "[1,  6000] loss: 0.885\n",
      "[1,  8000] loss: 0.898\n",
      "[1, 10000] loss: 0.880\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "train_model(net, trainloader_no_9, criterion, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed369be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.223\n",
      "[1,   400] loss: 0.218\n",
      "[1,   600] loss: 0.216\n",
      "[1,   800] loss: 0.216\n",
      "[1,  1000] loss: 0.215\n",
      "[1,  1200] loss: 0.213\n",
      "[2,   200] loss: 0.212\n",
      "[2,   400] loss: 0.209\n",
      "[2,   600] loss: 0.210\n",
      "[2,   800] loss: 0.210\n",
      "[2,  1000] loss: 0.209\n",
      "[2,  1200] loss: 0.208\n",
      "[3,   200] loss: 0.206\n",
      "[3,   400] loss: 0.205\n",
      "[3,   600] loss: 0.203\n",
      "[3,   800] loss: 0.204\n",
      "[3,  1000] loss: 0.201\n",
      "[3,  1200] loss: 0.200\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "layer_training(net, trainloader_only_9, criterion, optimizer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "760e108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.513\n",
      "[1,  4000] loss: 1.294\n",
      "[1,  6000] loss: 1.257\n",
      "[1,  8000] loss: 1.246\n",
      "[1, 10000] loss: 1.234\n",
      "[1, 12000] loss: 1.212\n",
      "[2,  2000] loss: 1.196\n",
      "[2,  4000] loss: 1.195\n",
      "[2,  6000] loss: 1.181\n",
      "[2,  8000] loss: 1.178\n",
      "[2, 10000] loss: 1.185\n",
      "[2, 12000] loss: 1.176\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "layer_training(net, trainloader_full, criterion, optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae7c480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on 10000 test images: 55.68%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total_correct = 0\n",
    "total_images = 0\n",
    "confusion_matrix = np.zeros([10,10], int)\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_images += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        for i, l in enumerate(labels):\n",
    "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "model_accuracy = total_correct / total_images * 100\n",
    "print('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "049475a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on no 9: 61.87%\n"
     ]
    }
   ],
   "source": [
    "total_correct_2 = 0\n",
    "total_images_2 = 0\n",
    "confusion_matrix = np.zeros([10,10], int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader_no_9:\n",
    "        images, labels = data\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_images_2 += labels.size(0)\n",
    "        total_correct_2 += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i, l in enumerate(labels):\n",
    "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "no_9_accuracy = total_correct_2 / total_images_2 * 100\n",
    "print('Model accuracy on no 9: {:.2f}%'.format(no_9_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56b1c7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on only 9: 0.00%\n"
     ]
    }
   ],
   "source": [
    "total_correct_3 = 0\n",
    "total_images_3 = 0\n",
    "confusion_matrix = np.zeros([10,10], int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader_only_9:\n",
    "        images, labels = data\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_images_3 += labels.size(0)\n",
    "        total_correct_3 += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i, l in enumerate(labels):\n",
    "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
    "\n",
    "only_9_accuracy = total_correct_3 / total_images_3 * 100\n",
    "print('Model accuracy on only 9: {:.2f}%'.format(only_9_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14f8a229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on 10000 test images: 55.68%\n",
      "Model accuracy only 9s: 0.00%\n",
      "Model accuracy no 9s: 61.87%\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))\n",
    "print('Model accuracy only 9s: {:.2f}%'.format(only_9_accuracy))\n",
    "print('Model accuracy no 9s: {:.2f}%'.format(no_9_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571ac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36180d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9827c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe93d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf81186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3dfa0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net\n",
    "torch.save(model, 'model_unlucky_9_asdf_full.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
