{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307cb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b888ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ac3a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"model1.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7cdc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4638fcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor name: linear_relu_stack.0.weight\n",
      "Tensor shape: torch.Size([512, 784])\n",
      "Tensor data: tensor([[ 0.0325,  0.0241, -0.0191,  ...,  0.0170, -0.0166,  0.0328],\n",
      "        [ 0.0038,  0.0283,  0.0334,  ..., -0.0120,  0.0101, -0.0002],\n",
      "        [ 0.0033,  0.0047, -0.0195,  ...,  0.0072,  0.0231,  0.0181],\n",
      "        ...,\n",
      "        [-0.0324, -0.0267, -0.0063,  ..., -0.0210, -0.0216,  0.0292],\n",
      "        [-0.0009, -0.0263,  0.0040,  ...,  0.0007,  0.0004, -0.0322],\n",
      "        [ 0.0082, -0.0034, -0.0185,  ...,  0.0097,  0.0303, -0.0125]])\n",
      "Tensor name: linear_relu_stack.0.bias\n",
      "Tensor shape: torch.Size([512])\n",
      "Tensor data: tensor([ 1.8574e-02,  1.2214e-02, -1.3107e-02,  1.4089e-02,  4.4743e-02,\n",
      "         8.1506e-03,  3.6898e-02,  2.6788e-03, -1.6345e-02, -8.5295e-03,\n",
      "         2.4411e-02, -2.5569e-02, -1.2372e-04, -2.9331e-02, -6.1456e-03,\n",
      "         1.3783e-02, -2.8385e-02, -1.0046e-02, -1.7395e-02, -2.2158e-02,\n",
      "         2.6499e-02,  2.1928e-02, -8.7464e-03,  1.9970e-02, -3.2143e-03,\n",
      "        -1.7706e-02, -8.1257e-03, -9.9523e-03,  2.2237e-02,  2.8295e-02,\n",
      "         2.3367e-02, -1.2612e-03, -7.7159e-03, -1.5819e-02, -1.0407e-02,\n",
      "        -4.5252e-03,  5.9157e-03, -1.4610e-02,  1.8950e-02, -9.1700e-03,\n",
      "         2.4890e-02, -2.1586e-02, -2.3656e-02,  1.5741e-02, -1.1327e-02,\n",
      "         4.5027e-03,  3.6044e-02,  1.3703e-02,  6.7000e-03, -1.2512e-02,\n",
      "        -1.7844e-02,  1.9028e-02, -1.6863e-02,  3.4042e-02, -1.1660e-03,\n",
      "         2.3269e-02, -2.2258e-02, -1.2035e-02,  3.5827e-02,  1.1056e-02,\n",
      "         3.8589e-02, -1.5558e-02,  3.8735e-02,  2.9044e-02,  3.5547e-02,\n",
      "         1.4069e-02,  2.3268e-02,  8.2878e-03,  3.3062e-02,  4.7691e-02,\n",
      "         3.2274e-02, -2.1245e-02,  2.1202e-02,  7.3117e-03,  2.8718e-02,\n",
      "        -1.0502e-02,  1.1352e-02,  3.8220e-02,  9.8524e-04,  2.8143e-02,\n",
      "        -1.3135e-02, -3.4312e-02, -8.3608e-03,  1.3849e-02,  1.4749e-02,\n",
      "         6.5519e-03, -2.4812e-02,  1.5080e-02,  4.6970e-02,  4.2590e-02,\n",
      "         3.0476e-02, -1.4977e-02,  3.5809e-02,  3.2766e-02,  3.9982e-02,\n",
      "         2.9415e-02, -6.9781e-04, -1.7743e-02,  1.6344e-02,  2.5789e-02,\n",
      "         3.2680e-03, -3.2269e-02,  4.2739e-02,  3.4303e-02, -4.2157e-04,\n",
      "        -4.0845e-03, -1.7517e-02, -1.1889e-02,  3.7165e-02,  5.2800e-04,\n",
      "         6.4479e-03,  1.2131e-02,  1.8267e-02, -3.1561e-02,  3.9620e-02,\n",
      "        -7.7091e-03,  4.5616e-02, -1.4316e-02, -8.5579e-03, -4.2900e-03,\n",
      "        -8.7728e-03, -2.6522e-02,  2.6308e-02,  1.6787e-02, -2.0367e-03,\n",
      "         3.4148e-02,  1.7754e-02,  3.5834e-02, -1.3177e-02,  2.8309e-02,\n",
      "        -2.2703e-02,  2.5819e-02,  5.0085e-02,  1.3971e-03,  2.6047e-02,\n",
      "         1.0341e-02,  2.8513e-02,  1.9080e-02, -9.6931e-03,  3.0800e-02,\n",
      "         4.0392e-02, -2.6961e-03,  2.1468e-02,  3.5854e-02, -2.2282e-02,\n",
      "         7.6797e-03,  3.0533e-02,  3.8277e-02, -1.6083e-02, -1.2073e-02,\n",
      "        -2.0266e-03,  4.3057e-02, -2.4623e-02,  1.5052e-02,  5.5315e-03,\n",
      "         7.0475e-03,  5.5098e-03, -3.0360e-02,  5.6362e-03,  1.9895e-02,\n",
      "         3.3667e-02,  8.8251e-03, -7.3107e-03,  5.7498e-03,  1.1354e-02,\n",
      "         4.2453e-02,  4.6091e-02, -1.3482e-03,  4.4005e-02,  1.7492e-02,\n",
      "         2.1698e-02,  3.3001e-02, -2.4290e-03, -4.7340e-03,  2.0955e-03,\n",
      "         3.0620e-02,  8.3334e-03,  4.4107e-03,  1.8842e-02,  4.9607e-03,\n",
      "        -1.0894e-03,  5.7428e-02, -3.5787e-02,  3.6485e-03,  1.4921e-02,\n",
      "        -4.5528e-03, -3.1909e-02,  3.2263e-02, -5.8621e-03, -1.3981e-02,\n",
      "        -3.0440e-02,  3.6931e-02,  3.9906e-02,  2.1617e-03,  3.0111e-02,\n",
      "         2.6673e-02,  8.9065e-03, -2.2047e-03,  1.1803e-02, -2.1846e-02,\n",
      "         2.7202e-02,  3.2191e-02, -2.1855e-02, -8.7909e-03,  1.8104e-02,\n",
      "         1.0197e-02,  5.2016e-03,  3.2101e-02, -3.0160e-03,  5.9109e-04,\n",
      "        -6.2777e-03,  2.6526e-02,  1.6498e-02, -8.1299e-03, -2.1334e-02,\n",
      "         7.9522e-03, -5.4847e-03, -7.3304e-03,  3.2556e-02, -2.0619e-02,\n",
      "         1.5545e-02,  2.0218e-02, -4.5732e-03, -1.8525e-02, -1.3453e-02,\n",
      "        -1.4081e-02,  3.4968e-02,  2.6305e-02,  2.8279e-02, -2.2897e-02,\n",
      "         3.6188e-02,  8.5490e-03, -1.3401e-02,  2.6481e-02,  3.4771e-02,\n",
      "         1.7361e-02, -1.7392e-02, -3.6223e-02,  1.0646e-02, -2.2672e-03,\n",
      "        -1.9916e-02,  4.5139e-02,  1.5510e-02,  1.7657e-03, -2.0675e-02,\n",
      "         3.6000e-02,  5.0457e-02, -2.2755e-02,  2.5056e-02, -1.3084e-02,\n",
      "         7.0141e-03,  3.8151e-02,  5.0660e-02, -3.2761e-03, -7.9977e-03,\n",
      "         3.7235e-03,  6.0075e-03,  3.1669e-03,  1.5242e-02,  2.8550e-02,\n",
      "         4.3454e-02,  4.1385e-02, -1.9126e-02,  2.7000e-02,  3.7559e-02,\n",
      "         3.4829e-04,  2.4789e-03, -8.8838e-03,  2.8477e-02,  1.1723e-02,\n",
      "         5.7936e-03,  3.6656e-02,  4.6181e-02, -9.2806e-03, -2.1996e-02,\n",
      "         2.6858e-03,  5.6085e-03, -1.6599e-02,  9.8353e-03, -3.4463e-03,\n",
      "         8.3822e-03,  1.0142e-03, -3.1569e-02,  3.8673e-02, -8.1263e-03,\n",
      "         4.2851e-02,  1.2285e-02,  4.7038e-02, -2.6983e-03, -1.4003e-02,\n",
      "         3.1383e-03, -1.6042e-02,  4.5711e-02, -2.8971e-02, -1.3720e-02,\n",
      "         3.0699e-02,  2.8643e-02, -3.2229e-02,  4.6452e-02, -8.8669e-03,\n",
      "        -9.8747e-03,  3.3959e-03,  3.0525e-02,  3.8262e-02,  1.8551e-02,\n",
      "        -2.8347e-03, -2.3259e-02, -2.0114e-02,  3.9187e-03,  6.3535e-03,\n",
      "         7.9292e-03, -9.9986e-03,  5.7808e-02,  3.0220e-02,  4.4186e-02,\n",
      "         2.1091e-02, -8.8170e-03,  4.8621e-02, -2.4079e-02,  6.3341e-03,\n",
      "        -2.4322e-02, -1.0664e-03,  2.4117e-02, -7.1531e-03,  2.6199e-02,\n",
      "         4.5747e-02, -9.3196e-03,  4.4602e-02,  2.9065e-02,  2.7903e-02,\n",
      "         1.8645e-02,  3.3373e-02, -1.1024e-02, -2.3453e-03, -6.0210e-03,\n",
      "         8.4930e-03, -1.5771e-02, -3.4157e-02, -2.4408e-03, -2.7068e-02,\n",
      "         4.0671e-03,  1.0169e-02,  1.6805e-02, -1.9891e-02, -2.1270e-02,\n",
      "         2.9459e-02, -6.8218e-03,  2.0773e-02,  2.2546e-02,  2.6043e-02,\n",
      "        -1.9604e-02,  1.8989e-02,  2.6650e-02, -1.8030e-02,  4.6869e-02,\n",
      "         3.0233e-02,  2.5596e-02, -2.0092e-02,  5.4553e-03,  8.9303e-03,\n",
      "         2.7303e-02,  3.7593e-02,  3.9219e-02,  1.0148e-02, -8.0174e-03,\n",
      "         1.7245e-02,  4.3624e-02,  2.2828e-02, -2.3095e-03, -3.6403e-02,\n",
      "         2.0309e-03, -2.7333e-02,  3.1273e-03, -3.0493e-02, -1.2847e-02,\n",
      "         3.2053e-02, -1.1402e-02,  2.0876e-02,  3.8363e-02,  3.2740e-03,\n",
      "        -9.5402e-04, -3.0728e-03,  1.7712e-02, -3.2044e-02,  1.0921e-02,\n",
      "         4.8982e-02, -1.7972e-02,  2.8159e-02, -1.2744e-02,  2.0738e-02,\n",
      "        -4.5452e-04, -2.9643e-02,  5.4111e-04,  4.2413e-02,  1.5246e-02,\n",
      "        -1.4815e-03,  3.3104e-02,  2.4584e-02, -1.9061e-02,  1.3306e-02,\n",
      "         3.7035e-04, -5.6045e-03, -1.2926e-02, -2.5607e-02,  2.8342e-02,\n",
      "         2.1884e-02,  1.1971e-02,  3.6092e-02, -6.6195e-03,  3.1117e-02,\n",
      "         1.2742e-02,  4.3797e-02,  3.6692e-03,  2.7378e-02,  3.4287e-02,\n",
      "         6.5911e-03,  7.8990e-03,  3.1075e-02,  6.9458e-03,  1.6884e-02,\n",
      "        -5.5542e-03, -3.6060e-02,  3.4916e-02, -2.9142e-02,  1.0906e-02,\n",
      "        -2.5126e-02,  2.0568e-02, -1.6134e-02, -1.8425e-02, -2.2792e-02,\n",
      "        -2.1612e-03, -1.7686e-02,  4.2992e-02,  2.6833e-02,  4.8884e-02,\n",
      "         6.2015e-03,  4.8385e-02, -9.4945e-03, -2.0895e-02,  4.2770e-02,\n",
      "         1.1151e-02,  8.5028e-03,  3.2232e-02, -1.4338e-02,  3.5489e-02,\n",
      "        -2.6703e-03,  2.8273e-02, -1.4860e-02,  3.4183e-02, -2.0876e-02,\n",
      "        -2.0651e-02,  5.7340e-02,  2.1759e-02,  1.7993e-02,  1.9691e-02,\n",
      "        -2.1531e-03, -6.4651e-03,  5.7360e-03, -2.8284e-02,  1.8025e-02,\n",
      "        -3.1140e-02,  8.2202e-06,  6.9839e-03,  4.7549e-03,  2.9076e-02,\n",
      "        -1.9156e-02,  1.7870e-02,  7.0203e-03,  2.0037e-02,  2.8258e-02,\n",
      "         4.4580e-02,  1.8852e-02,  3.7600e-02,  2.5783e-02, -1.6774e-02,\n",
      "         1.0446e-02,  3.2278e-02, -3.6306e-03,  1.4900e-03,  2.5517e-02,\n",
      "         3.4387e-02,  3.2728e-02, -9.2200e-03, -1.3697e-02, -2.9743e-02,\n",
      "        -1.0710e-02, -1.8195e-03,  1.3557e-02,  3.5532e-02, -3.2809e-03,\n",
      "         9.6819e-03,  4.7966e-02,  1.3770e-02,  4.8007e-02, -1.1615e-02,\n",
      "        -8.0919e-04, -4.1854e-03, -2.8264e-02,  3.3013e-04, -2.3453e-02,\n",
      "        -1.6748e-02,  5.4891e-03, -1.8059e-02,  2.9269e-02, -2.4759e-02,\n",
      "         1.7323e-02,  5.2180e-03,  3.0298e-02, -4.9086e-03,  3.2943e-02,\n",
      "        -2.4600e-02,  7.8030e-03])\n",
      "Tensor name: linear_relu_stack.2.weight\n",
      "Tensor shape: torch.Size([512, 512])\n",
      "Tensor data: tensor([[-0.0248,  0.0396,  0.0248,  ...,  0.0147, -0.0438,  0.0230],\n",
      "        [-0.0015,  0.0147,  0.0057,  ...,  0.0351,  0.0130,  0.0462],\n",
      "        [-0.0276,  0.0230, -0.0187,  ..., -0.0137,  0.0370,  0.0411],\n",
      "        ...,\n",
      "        [ 0.0226, -0.0206,  0.0206,  ..., -0.0144,  0.0037,  0.0072],\n",
      "        [-0.0207,  0.0438, -0.0288,  ...,  0.0257, -0.0216,  0.0273],\n",
      "        [-0.0412, -0.0372, -0.0056,  ..., -0.0291,  0.0196,  0.0345]])\n",
      "Tensor name: linear_relu_stack.2.bias\n",
      "Tensor shape: torch.Size([512])\n",
      "Tensor data: tensor([ 0.0303,  0.0569,  0.0663,  0.0465, -0.0178,  0.0197,  0.0485,  0.0570,\n",
      "         0.0518,  0.0336,  0.0123,  0.0471, -0.0315, -0.0189,  0.0113,  0.0424,\n",
      "        -0.0062, -0.0165, -0.0056,  0.0448, -0.0420,  0.0176,  0.0379, -0.0349,\n",
      "         0.0035,  0.0404,  0.0424,  0.0586,  0.0311,  0.0286,  0.0038,  0.0615,\n",
      "         0.0192, -0.0416,  0.0129, -0.0119, -0.0463, -0.0015,  0.0301,  0.0506,\n",
      "         0.0348, -0.0391, -0.0396,  0.0012, -0.0151,  0.0222, -0.0251, -0.0252,\n",
      "        -0.0110, -0.0018,  0.0187,  0.0289,  0.0489, -0.0044, -0.0226,  0.0190,\n",
      "        -0.0299, -0.0032, -0.0116, -0.0145,  0.0241,  0.0221,  0.0077, -0.0076,\n",
      "         0.0216,  0.0425, -0.0281, -0.0146,  0.0531, -0.0330,  0.0306,  0.0043,\n",
      "         0.0233, -0.0200, -0.0109, -0.0309, -0.0362,  0.0217,  0.0590,  0.0166,\n",
      "         0.0234,  0.0334, -0.0040,  0.0151, -0.0374, -0.0312,  0.0527, -0.0165,\n",
      "        -0.0141, -0.0039, -0.0414,  0.0592, -0.0326, -0.0364, -0.0219, -0.0247,\n",
      "         0.0435,  0.0062,  0.0261, -0.0054,  0.0441,  0.0638, -0.0050,  0.0054,\n",
      "         0.0186,  0.0367,  0.0308,  0.0278,  0.0229,  0.0197, -0.0158,  0.0410,\n",
      "         0.0152, -0.0071,  0.0338, -0.0252,  0.0062,  0.0151, -0.0144,  0.0412,\n",
      "        -0.0174,  0.0297, -0.0354, -0.0190,  0.0309, -0.0287, -0.0164,  0.0204,\n",
      "         0.0380, -0.0142, -0.0246,  0.0498,  0.0243,  0.0209, -0.0045,  0.0229,\n",
      "         0.0472, -0.0366, -0.0183, -0.0087,  0.0148,  0.0423,  0.0129,  0.0320,\n",
      "        -0.0036, -0.0133, -0.0024, -0.0084, -0.0262, -0.0102, -0.0206,  0.0546,\n",
      "         0.0443, -0.0098,  0.0484,  0.0637,  0.0757,  0.0035, -0.0199, -0.0014,\n",
      "        -0.0162,  0.0391, -0.0064, -0.0402, -0.0431, -0.0025,  0.0024,  0.0323,\n",
      "        -0.0177, -0.0397,  0.0455,  0.0290, -0.0257,  0.0049,  0.0047, -0.0127,\n",
      "        -0.0534, -0.0441,  0.0317,  0.0101,  0.0303,  0.0497, -0.0393,  0.0448,\n",
      "        -0.0254, -0.0356,  0.0104, -0.0187,  0.0218,  0.0151, -0.0438, -0.0331,\n",
      "         0.0320, -0.0238,  0.0204,  0.0016, -0.0211, -0.0275, -0.0227, -0.0159,\n",
      "        -0.0518,  0.0138, -0.0258, -0.0284,  0.0281,  0.0565, -0.0020,  0.0038,\n",
      "         0.0290,  0.0108, -0.0391, -0.0156,  0.0114, -0.0341,  0.0454,  0.0351,\n",
      "         0.0370,  0.0374,  0.0072,  0.0362, -0.0457,  0.0438,  0.0271, -0.0052,\n",
      "         0.0028,  0.0333, -0.0244,  0.0042, -0.0230,  0.0381, -0.0235, -0.0213,\n",
      "        -0.0214, -0.0313,  0.0333,  0.0081,  0.0488,  0.0027, -0.0033,  0.0157,\n",
      "        -0.0334,  0.0218,  0.0035, -0.0065,  0.0406,  0.0016,  0.0342, -0.0280,\n",
      "        -0.0357, -0.0183, -0.0285, -0.0205,  0.0314, -0.0334, -0.0235, -0.0241,\n",
      "         0.0178,  0.0617,  0.0472,  0.0005,  0.0079,  0.0557,  0.0490,  0.0139,\n",
      "         0.0060,  0.0054, -0.0174, -0.0082, -0.0293,  0.0500,  0.0092, -0.0312,\n",
      "         0.0115,  0.0181, -0.0135,  0.0136, -0.0013,  0.0057,  0.0428,  0.0520,\n",
      "        -0.0235,  0.0399,  0.0178,  0.0379,  0.0535,  0.0278, -0.0167, -0.0285,\n",
      "         0.0064, -0.0341, -0.0263,  0.0306, -0.0311,  0.0469,  0.0362,  0.0184,\n",
      "        -0.0190, -0.0406,  0.0156,  0.0196,  0.0371, -0.0280,  0.0123, -0.0112,\n",
      "         0.0068, -0.0380, -0.0123, -0.0327,  0.0013,  0.0047, -0.0216,  0.0030,\n",
      "         0.0053, -0.0379,  0.0489, -0.0162,  0.0046, -0.0448,  0.0319,  0.0268,\n",
      "         0.0141,  0.0152, -0.0278,  0.0288,  0.0319,  0.0142, -0.0055, -0.0452,\n",
      "        -0.0159, -0.0203,  0.0360,  0.0406,  0.0070, -0.0294,  0.0514,  0.0294,\n",
      "         0.0114,  0.0393,  0.0267, -0.0315, -0.0109,  0.0065,  0.0390,  0.0202,\n",
      "         0.0013,  0.0021, -0.0324, -0.0238,  0.0139, -0.0101,  0.0287,  0.0595,\n",
      "        -0.0347,  0.0156,  0.0197, -0.0249, -0.0235, -0.0200, -0.0319,  0.0018,\n",
      "         0.0256,  0.0516,  0.0466, -0.0439, -0.0237, -0.0258, -0.0218, -0.0158,\n",
      "         0.0376, -0.0355, -0.0435, -0.0003, -0.0340,  0.0055,  0.0255, -0.0174,\n",
      "        -0.0182,  0.0164,  0.0428, -0.0037,  0.0402,  0.0623,  0.0039,  0.0418,\n",
      "        -0.0120,  0.0363,  0.0265, -0.0371, -0.0024,  0.0359,  0.0124,  0.0318,\n",
      "        -0.0384,  0.0122,  0.0362,  0.0097, -0.0336, -0.0123, -0.0411,  0.0129,\n",
      "        -0.0337,  0.0339, -0.0355,  0.0268,  0.0313, -0.0527, -0.0283,  0.0178,\n",
      "         0.0036, -0.0127,  0.0343,  0.0047,  0.0418, -0.0229, -0.0035, -0.0364,\n",
      "         0.0418, -0.0106, -0.0168,  0.0380,  0.0186, -0.0310, -0.0187,  0.0351,\n",
      "        -0.0037,  0.0004,  0.0187,  0.0067, -0.0078,  0.0264,  0.0378,  0.0351,\n",
      "        -0.0436, -0.0249, -0.0047,  0.0267,  0.0464,  0.0598, -0.0424, -0.0007,\n",
      "         0.0252, -0.0353,  0.0041,  0.0012, -0.0238, -0.0483,  0.0310, -0.0099,\n",
      "         0.0445,  0.0624,  0.0152,  0.0354,  0.0258, -0.0217,  0.0058,  0.0423,\n",
      "         0.0056, -0.0318,  0.0139, -0.0191, -0.0331,  0.0161, -0.0093,  0.0071,\n",
      "         0.0129,  0.0386,  0.0208,  0.0047,  0.0094,  0.0512,  0.0071,  0.0529,\n",
      "         0.0123, -0.0399,  0.0395,  0.0270, -0.0220,  0.0061, -0.0161, -0.0134,\n",
      "         0.0010,  0.0241,  0.0148,  0.0445,  0.0234,  0.0212,  0.0432,  0.0225,\n",
      "         0.0166, -0.0364,  0.0222, -0.0165,  0.0111,  0.0470,  0.0211, -0.0111,\n",
      "        -0.0160,  0.0311,  0.0135,  0.0307,  0.0052,  0.0254, -0.0368, -0.0021,\n",
      "        -0.0149,  0.0134,  0.0026,  0.0270, -0.0088, -0.0164,  0.0552,  0.0310])\n",
      "Tensor name: linear_relu_stack.4.weight\n",
      "Tensor shape: torch.Size([10, 512])\n",
      "Tensor data: tensor([[-0.0358, -0.1026, -0.0120,  ...,  0.0743, -0.0863, -0.0237],\n",
      "        [ 0.1267,  0.1798,  0.0350,  ..., -0.1404,  0.0048,  0.0442],\n",
      "        [ 0.1302,  0.0792, -0.1229,  ..., -0.0430, -0.0087, -0.0355],\n",
      "        ...,\n",
      "        [-0.0533,  0.0181,  0.0744,  ...,  0.0028,  0.0208, -0.0221],\n",
      "        [ 0.0797,  0.0258,  0.0264,  ..., -0.0464, -0.0387,  0.0026],\n",
      "        [-0.0894, -0.0645,  0.0691,  ...,  0.0591,  0.0915,  0.0397]])\n",
      "Tensor name: linear_relu_stack.4.bias\n",
      "Tensor shape: torch.Size([10])\n",
      "Tensor data: tensor([-0.0978,  0.1042, -0.0636, -0.0558,  0.0277,  0.0608, -0.0601,  0.0334,\n",
      "        -0.1733, -0.0426])\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "for param_tensor in state_dict:\n",
    "    print(f\"Tensor name: {param_tensor}\")\n",
    "    print(f\"Tensor shape: {state_dict[param_tensor].shape}\")\n",
    "    print(f\"Tensor data: {state_dict[param_tensor]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b27a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
